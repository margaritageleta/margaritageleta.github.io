
<!DOCTYPE html>
<html lang="en" class="no-js">
	<head>
		<title>3omni</title>
		<script src="../js/loadTags.js"></script>
		<script id="head">
			loadMetaTags();
			loadLibraries();
			loadScripts();
		</script>

		<link rel="stylesheet" type="text/css" href="../css/style.css">
		<script src="https://kit.fontawesome.com/ae7c3de316.js" crossorigin="anonymous"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.1.0/js-yaml.min.js" integrity="sha512-CSBhVREyzHAjAFfBlIBakjoRUKp5h7VSweP0InR/pAJyptH7peuhCsqAI/snV+TwZmXZqoUklpXp6R6wMnYf5Q==" crossorigin="anonymous"></script>
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
		<script src="../js/colorUtils/color.min.js"></script>
		<script src="../js/colorUtils/colorize.js"></script>
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<!--<link href="https://fonts.googleapis.com/css2?family=Quicksand:wght@300;400;500;600;700&display=swap" rel="stylesheet"> -->
		<link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap" rel="stylesheet"> 
        <style>
            img {
                box-shadow: none !important;
            }
        </style>
    </head>
	<body id="body"> <!--onload="randomize();"-->	
		<nav>
			<!--<div>
				<a href="index.html">
					<div>
						<p>About</p>
						<div></div>
					</div>
				</a>
				<a href="art.html">
					<div>
						<p>Art</p>
						<div></div>
					</div>
				</a>
			</div>-->
			<div class="bio">
				<div class="wrapper">
					<div class="wrapped">
						<h2><a href="index.html" style="color: black !important;">Margarita Geleta</a></h2>
						<div class="wrapper">
							<div id="bio-image" class="wrapped"></div>
						</div>
						<p><b>TL;DR</b>: I am a CS PhD student at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>. My main research interest is generative modelling. </p>
						<br>
						<p>I worked at <a href="https://www.amazon.science/author/margarita-geleta">Amazon</a> as an Applied Scientist in HIT, and at <a href="https://profiles.stanford.edu/intranet/margarita-geleta?releaseVersion=9.9.1">Stanford</a> as a Research Assistant in the Biomedical Data Science department.</p> 
						<br>
						<p>I did my undergrad at <a href="https://www.upc.edu/en">UPC BarcelonaTech</a> and researched in the <a href="https://imatge.upc.edu/web/biblio?f%5Bauthor%5D=1540">Image UPC</a> group. Before transferring to Berkeley, I started grad school at <a href="https://uci.edu/">UC Irvine</a> where I worked in the <a href="https://etad.calit2.uci.edu/lab-members/graduate-researchers/">ETAD</a> lab and collaborated with the <a href="https://ucinlp.github.io/">UCI NLP</a> group.</p>
						<br>
						<div class="bio-linkspace">
							<div>
									<ul>
										<li><a href="https://es.linkedin.com/in/margarita-geleta" target="_blank" rel="noopener noreferrer">
											<i class="fa fa-linkedin"></i> 
											<span>Linkedin</span></a>
										</li>
										<li><a href="https://twitter.com/ritageleta" target="_blank" rel="noopener noreferrer">
											<i class="fa fa-twitter"></i> 
											<span>Twitter</span></a>
										</li>
										<li><a href="https://github.com/margaritageleta" target="_blank" rel="noopener noreferrer">
											<i class="fa fa-github"></i> 
											<span>GitHub</span></a>
										</li>
										<li><a href="https://docs.google.com/viewer?url=https://raw.githubusercontent.com/margaritageleta/cv/master/resume22.pdf" target="_blank" rel="noopener noreferrer">
											<i class="fa fa-file"></i>
											<span>Resume</span>
										</a></li>
										<li><a href="https://docs.google.com/viewer?url=https://raw.githubusercontent.com/margaritageleta/cv/master/CV.pdf" target="_blank" rel="noopener noreferrer">
											<i class="fa fa-file"></i>
											<span>CV</span>
										</a></li>
									</ul>
							</div>	
						</div>
					
						<!--<p>The rule I follow in my everyday life is <b>"whatever you can do today, do not leave it until tomorrow"</b>. I always seek for new opportunities and I crave for learning. My interests fall in the domain of Data Science and Machine Learning - the exciting intersection of Computer Science and Statistics. </p>-->
						</p>
					</div>	
				</div>
			</div>
			
		</nav>
		<main id="main">
			<div class="bg_white" style="width: 100%;">
				
				<div class="wrapper linkspace">
					<div class="wrapped">
						<ul>
							<li><a href="../index.html">
								<i class="fa fa-bookmark"></i> 
								<span>Research</span></a>
							</li>
							<li><a href="../projects.html">
								<i class="fa fa-heart"></i> 
								<span>Projects</span></a>
							</li>
							<li><a href="../art.html">
								<i class="fa fa-palette"></i> 
								<span>Art</span></a>
							</li>
							<li><a href="../about.html">
								<i class="fa fa-question"></i> 
								<span>More about me</span></a>
							</li>
						</ul>
					</div>
				</div>	
				<div class="corners__wrapper">
					<div class="corner"></div>
					<div class="corner"></div>
				</div>
			</div>
			<div class="bottom__hero">
				<div class="ghost-nav"></div>

				<div class="wrapper">
					<div class="wrapped article">
						<div class="wrapper">
                            <div class="wrapped">
                                <h2>Colorizinâ€‹g Old Photos</h2>
								<div class="bookmarks">
									<!--<ol>
										<li><a href="#what">What is Toxic Language?</a></li>
										<li><a href="#whatfeat">What are the features of Toxic Language?</a></li>
										<li><a href="#kernels">String Kernels</a></li>
									</ol>-->
									<div>
									</div>
								</div>
                                <h3 id="what">About the Prokudin-Gorskii collection</h3>
                                <p>Sergei Mikhailovich Prokudin-Gorskii (1863-1944) was a pioneer in color photography. In 1907, he won Tzar's special permission to travel across the vast Russian Empire and take color photographs of everything he saw including the only color portrait of Leo Tolstoy. And he really photographed everything: people, buildings, landscapes, railroads, bridges... thousands of color pictures! His idea was simple: record three exposures of every scene onto a glass plate using a red, a green, and a blue filter. Never mind that there was no way to print color photographs until much later.</p> 
                                <p>His negatives have been digitized and are <a href="https://www.loc.gov/collections/prokudin-gorskii/" target="_blank" rel="noopener noreferrer">available on-line</a>.</p>
                                <h3>Automatic alignment of film exposures</h3>
                                <p>First of all, we need to extract the film exposures from the negatives and place them on top of each other, and align them so that they form a single color image, taking into account that the orders of the filters in the images from top to bottom is blue, green, red (not the conventional red, green, blue).</p>
                                <div class="article-content">
									<img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/onion_church.png?raw=true" alt="Filters from negative"> 
								</div>

                                <p>A naive way of aligning to images is trying a set of pixel shifts in both, x and y, directions, and measuring how well they're aligned. One such metric is the a pixelwise L2 norm, or sum of squared differences (SSD) which is computed by taking the pixelwise difference between two images and returning the squared norm of the result. </p>
                                <p>Unfortunately, this metric can compare only two images at a time, not three. Thus, we have to treat one color channel as a reference channel and then use the metric to align the other two channels to the reference channel. For instance, if the blue channel is our reference, we will align the red to the blue and then align the green to the blue. Interestingly, selecting different references results in different alignments. </p>
                                <p>Below you can see (from left to right) the three film exposures (red, green, blue) and, on the second row, automatic aligment using the reference channel red, green and blue, respectively.</p>
								
								<div class="article-content">
									<img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/monastery.png?raw=true" alt="Filters from negative"> 
								</div>
                                <p>Empirically, I found that taking the green channel as the reference channel gave the smallest SSD and more consistent results.</p>

                                <h3>Image Pyramid</h3>
                                <p>While this scoring metric worked well on low-resolution images, the exhaustive search became prohibitively expensive on the full-resolution glass scans. To that end, an image pyramid technique is a good option. The idea is to recurse down to a low-resolution image, find the best alignment there and then use the best alignment as a starting point in the next higher-resolution level alignment.</p>
                                <div class="article-content">
									<img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/train_smart_crop.png?raw=true" alt="Filters from negative"> 
								</div>
                            
                                <h3>Smart Cropping</h3>
                                <p>Most of the images have boundaries which would be great to get rid of in an automatic way. I used 2 stategies to perform this "smart" cropping.</p>
                                <ul>
                                    <li><b>Remove uni-color boundaries</b>: first, find the pixels that have at least one very dark layer. Such pixels are considered candidates in the boundary. Then scan through each row and column where these pixels are located. If the proportion of the candidate boundary pixels is more than 80%, this row/column is regarded as boundary and is cropped out.</li>
                                    <li><b>Remove edge boundaries detected via Sobel</b>: second, take the middle row and column of the image and apply a Sobel filter. Find the highest activations boundaries at the edges and crop them out.</li>
                                </ul>
                                <p>Here are some results of smart cropping:</p>
                                <div class="article-content">
									<img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/samarkand_smart_crop.png?raw=true" alt="Smart cropping"> 
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/self_portrait_smart_crop.png?raw=true" alt="Smart cropping"> 
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/emir_smart_crop_sobel.png?raw=true" alt="Smart cropping">
                                </div>

                                <h3>Automatic sharpening and contrasting</h3>
                                <p>Next step to enhance the pictures, I convolved each channel with a sharpening filter and applied high dynamic range (HDR) imaging, which is a technique used in photography to reproduce a greater dynamic range of luminosity than is possible with standard digital imaging. Essentially, HDR is histogram equalization and it enhances the contrast of our images.</p>
                                <p>See the results next:</p>
                                <div class="article-content">
									<img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/emir_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/harvesters_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/icon_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/krestianki_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/lady_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/melons_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/onion_church_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/samarkand1905_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/self_portrait_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/three_generations_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/train_equalized.png?raw=true" alt="hdr">
                                    <img src="https://github.com/margaritageleta/computer-vision/blob/main/proj1/outputs/workshop_equalized.png?raw=true" alt="hdr">
                                </div>
                            </div>
						</div>
						
						<div class="wrapper">
							<div class="wrapped">
								<p>If you have any ideas or comments regarding this work, don't hesitate to contact me.</p>
							</div>
						</div>
					</div>	
				</div>
			</div>	
		</main>
	</body>
</html>